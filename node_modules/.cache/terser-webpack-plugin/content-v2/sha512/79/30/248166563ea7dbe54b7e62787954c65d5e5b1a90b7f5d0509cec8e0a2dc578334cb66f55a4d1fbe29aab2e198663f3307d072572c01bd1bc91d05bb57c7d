{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[78],{360:function(t,s,a){\"use strict\";a.r(s);var n=a(14),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":t.$parent.slotKey}},[a(\"h2\",{attrs:{id:\"线程安全的集合类\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#线程安全的集合类\"}},[t._v(\"#\")]),t._v(\" 线程安全的集合类\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"写时复制-copyonwritearraylist\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#写时复制-copyonwritearraylist\"}},[t._v(\"#\")]),t._v(\" 写时复制 CopyOnWriteArrayList\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[a(\"p\",[t._v(\"多线程下，普通的List不满足线程安全的需要，可能会抛出\"),a(\"code\",[t._v(\"ConcurrentModificationException\")]),t._v(\"异常，通常情况下有三种解决方案\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[t._v(\"Vector 线程安全的集合（效率低）\")]),t._v(\" \"),a(\"li\",[t._v(\"Collections.synchronizedList(new ArrayList<>()) 工具类\")]),t._v(\" \"),a(\"li\",[t._v(\"CopyOnWriteArrayList JUC下的线程安全类\")])])]),t._v(\" \"),a(\"li\",[a(\"p\",[t._v(\"CopyOnWriteArrayList核心思想是读写分离\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[t._v(\"在做写时加锁，不直接往当前容器Object[]添加，而是对容器进行copy +1,把新元素放入copy的新容器中，添加完元素原容器的引用指向新的容器。而其读是无锁的，性能高。\")]),t._v(\" \"),a(\"li\",[t._v(\"缺点是：每次写入都有copy一份容器，数据量大时，对内存压力较大。2 可能无法保持实时性，Vector读写都加锁，而CopyOnWriteArrayList读写作用在新老容器上，并发时可能读不到最新数据\")])])]),t._v(\" \"),a(\"li\",[a(\"p\",[t._v(\"CopyOnWriteArrayList Add()方法\")])])]),t._v(\" \"),a(\"div\",{staticClass:\"language-java extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[a(\"code\",[t._v(\"    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"public\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"boolean\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"E\")]),t._v(\" e\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"final\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"ReentrantLock\")]),t._v(\" lock \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"this\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"lock\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//上锁\")]),t._v(\"\\n        lock\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"lock\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"try\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//获取原有数组\")]),t._v(\"\\n            \"),a(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Object\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" elements \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getArray\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" len \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" elements\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"length\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//复制一份+1\")]),t._v(\"\\n            \"),a(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Object\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" newElements \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Arrays\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"copyOf\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"elements\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" len \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            newElements\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"len\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" e\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//设置新的array为+1的\")]),t._v(\"\\n            \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"setArray\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"newElements\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[t._v(\"true\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"finally\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            lock\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"unlock\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])]),a(\"h3\",{attrs:{id:\"concurrenthashmap\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#concurrenthashmap\"}},[t._v(\"#\")]),t._v(\" ConcurrentHashMap\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[t._v(\"线程安全的map同样可以使用\\n\"),a(\"ul\",[a(\"li\",[t._v(\"HashTable 读写都用synchronized，效率低下\")]),t._v(\" \"),a(\"li\",[t._v(\"ConcurrentHashMap 使用了锁分离技术，多个锁控制对hash表的不同部分进行的修改\")])])]),t._v(\" \"),a(\"li\",[t._v(\"ConcurrentHashMap 中对map进行了分段Segment，每个Segment本身相当一个HashMap对象，\"),a(\"strong\",[t._v(\"同一Segment只有写写互斥，读读是不互斥的，不同Segment不互斥\")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);","extractedComments":[]}